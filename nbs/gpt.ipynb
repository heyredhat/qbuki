{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd56d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb9d4f",
   "metadata": {},
   "source": [
    "# GPT\n",
    "\n",
    "> description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6d4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060a0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9790cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial import HalfspaceIntersection\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jp\n",
    "from jax.config import config\n",
    "config.update('jax_platform_name', 'cpu')\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import mpl_toolkits.mplot3d as a3\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from qbuki.utils import *\n",
    "from qbuki.random import *\n",
    "\n",
    "def gpt_full_rank_decomposition(M):\n",
    "    Q, R = np.linalg.qr(M.T)\n",
    "    R *= Q[0,0] \n",
    "    Q /= Q[0,0]\n",
    "    B, C = full_rank_decomposition(Q[:, 1:] @ R[1:, ])\n",
    "    S = np.hstack([Q[:,0:1], B]).T\n",
    "    E = np.vstack([R[0:1,:], C]).T\n",
    "    return E, S \n",
    "\n",
    "def dual_halfspace_intersection(points):\n",
    "    points = np.array([pt for pt in points if not np.allclose(pt, np.zeros(points.shape[1]))])\n",
    "    n = len(points)\n",
    "    halfspaces = np.vstack([np.hstack([-points, np.zeros(n).reshape(n,1)]),\n",
    "                            np.hstack([points, -np.ones(n).reshape(n,1)])])\n",
    "    return HalfspaceIntersection(halfspaces, interior_point(halfspaces))\n",
    "\n",
    "def plot_convex_hull(hull, points=None, fill=True, ax=None):\n",
    "    points = hull.points if type(points) == type(None) else points\n",
    "    d = points.shape[1]\n",
    "\n",
    "    if type(ax) == type(None):\n",
    "        fig = plt.figure()\n",
    "        if d == 3:\n",
    "            ax = fig.add_subplot(111, projection=\"3d\") \n",
    "        else:    \n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "    ax.plot(*[points[:,i] for i in range(d)], 'bo')\n",
    "\n",
    "    if d == 3:\n",
    "        if fill:\n",
    "            c = colors.rgb2hex(sc.rand(3))\n",
    "            for simplex in hull.simplices:\n",
    "                f = a3.art3d.Poly3DCollection([[[points[simplex[i], j] for j in range(d)] for i in range(d)]])\n",
    "                f.set_color(c)\n",
    "                f.set_edgecolor('k')\n",
    "                f.set_alpha(0.4)\n",
    "                ax.add_collection3d(f)\n",
    "        else:\n",
    "            for simplex in hull.simplices:\n",
    "                ax.plot(*[points[simplex, i] for i in range(d)], 'black')\n",
    "    else:\n",
    "        for simplex in hull.simplices:\n",
    "            ax.plot(*[points[simplex, i] for i in range(d)], 'black')\n",
    "        plt.fill(*[points[hull.vertices,i] for i in range(d)], color=colors.rgb2hex(sc.rand(3)), alpha=0.3)\n",
    "    return ax\n",
    "\n",
    "def rank_approximation(P, k, sd=1, tol=1e-6, max_iter=1000, verbose=False):\n",
    "    m, n = P.shape\n",
    "    S = np.random.randn(m, k)\n",
    "    E = np.random.randn(k, n)\n",
    "    W = np.eye(m*n)/sd**2 \n",
    "    t = 0; last = None\n",
    "    while t < max_iter:\n",
    "        try:\n",
    "            U = np.kron(E, np.eye(m)) @ W @ np.kron(E.T, np.eye(m))\n",
    "            V = -2*np.kron(E, np.eye(m)) @ W @ P.T.flatten()\n",
    "            Y = np.kron(E.T,np.eye(m))\n",
    "\n",
    "            Svec = cp.Variable(k*m)\n",
    "            Sprob = cp.Problem(cp.Minimize(cp.quad_form(Svec, U) + V.T @ Svec), [0 <= Y @ Svec, Y @ Svec <= 1])\n",
    "            Sresult = Sprob.solve()\n",
    "            S = Svec.value.reshape(k, m).T\n",
    "\n",
    "            U = np.kron(np.eye(n), S).T @ W @ np.kron(np.eye(n), S)\n",
    "            V = -2*np.kron(np.eye(n), S).T @ W @ P.T.flatten()\n",
    "            Y = np.kron(np.eye(n), S)\n",
    "\n",
    "            Evec = cp.Variable(k*n)\n",
    "            Eprob = cp.Problem(cp.Minimize(cp.quad_form(Evec, U) + V.T @ Evec), [0 <= Y @ Evec, Y @ Evec <= 1])\n",
    "            Eresult = Eprob.solve()\n",
    "            E = Evec.value.reshape(n,k).T\n",
    "            if verbose and t % 100 == 0:\n",
    "                print(\"%d: chi_S = %f | chi_E = %f \" % (t, Sresult, Eresult))\n",
    "\n",
    "            if type(last) != type(None) and abs(Sresult-last[0]) <= tol and abs(Eresult-last[1]) <= tol and not np.isclose(np.sum(S @ E),0):\n",
    "                break\n",
    "            last = [Sresult, Eresult]\n",
    "        except:\n",
    "            S = np.random.randn(m, k)\n",
    "            E = np.random.randn(k, n)\n",
    "            continue\n",
    "        t += 1\n",
    "    return S @ E\n",
    "\n",
    "class GPT:\n",
    "    @classmethod\n",
    "    def from_probability_table(cls, P):\n",
    "        effects, states = gpt_full_rank_decomposition(P)\n",
    "        return GPT(effects, states)\n",
    "\n",
    "    def __init__(self, effects, states, unit_effect=None, maximally_mixed_state=None):\n",
    "        self.unit_effect = unit_effect if type(unit_effect) != type(None) else \\\n",
    "                           np.eye(states.shape[0])[0]\n",
    "        self.maximally_mixed_state = maximally_mixed_state if type(maximally_mixed_state) != type(None) else \\\n",
    "                                     np.mean(states, axis=1)\n",
    "        self.effects = np.vstack([effects, self.unit_effect - effects])\n",
    "        self.states = states\n",
    "\n",
    "        self.state_space = ConvexHull(self.states.T[:, 1:])\n",
    "        self.effect_space = ConvexHull(self.effects)\n",
    "\n",
    "        self.logical_states = dual_halfspace_intersection(self.effects)\n",
    "        self.logical_effects = dual_halfspace_intersection(self.states.T)\n",
    "\n",
    "        self.logical_state_space = ConvexHull(self.logical_states.intersections[:, 1:])\n",
    "        self.logical_effect_space = ConvexHull(self.logical_effects.intersections)\n",
    "    \n",
    "        self.d = self.states.shape[0]\n",
    "\n",
    "    def sample_measurement(self, m, max_iter=100):\n",
    "        if m == 1:\n",
    "            return sample_convex_hull(self.effect_space, 1)\n",
    "\n",
    "        A = self.effect_space.equations[:, :-1]\n",
    "        b = self.effect_space.equations[:, -1]\n",
    "        B = np.tile(b, (m,1)).T\n",
    "        \n",
    "        @jax.jit\n",
    "        def unity(V):\n",
    "            M = V.reshape(m, self.d)\n",
    "            return jp.linalg.norm(jp.sum(M, axis=0) - self.unit_effect)**2\n",
    "\n",
    "        @jax.jit\n",
    "        def consistency(V):\n",
    "            M = V.reshape(m, self.d)\n",
    "            return (- A @ M.T - B).flatten()\n",
    "\n",
    "        i = 0\n",
    "        while i < max_iter:\n",
    "            V = np.random.randn(m*self.d)\n",
    "            result = sc.optimize.minimize(unity, V,\\\n",
    "                                jac=jax.jit(jax.jacrev(unity)),\\\n",
    "                                tol=1e-16,\\\n",
    "                                constraints=[{\"type\": \"ineq\",\\\n",
    "                                                \"fun\": consistency,\\\n",
    "                                                \"jac\": jax.jit(jax.jacrev(consistency))}],\\\n",
    "                                options={\"maxiter\": 5000},\n",
    "                                method=\"SLSQP\")\n",
    "            M = result.x.reshape(m, self.d)\n",
    "            if self.valid_measurement(M):\n",
    "                return M\n",
    "            i += 1\n",
    "    \n",
    "    def valid_measurement(self, M):\n",
    "        m = M.shape[0]\n",
    "        A = self.effect_space.equations[:, :-1]\n",
    "        b = self.effect_space.equations[:, -1]\n",
    "        B = np.tile(b, (m,1)).T\n",
    "        return np.all((- A @ M.T - B).flatten() >= 0) and np.allclose(np.sum(M, axis=0), self.unit_effect)\n",
    "\n",
    "    def sample_logical_measurement(self, m, max_iter=100):\n",
    "        if m == 1:\n",
    "            return sample_convex_hull(self.logical_effect_space, 1)\n",
    "\n",
    "        @jax.jit\n",
    "        def unity(V):\n",
    "            M = V.reshape(m, self.d)\n",
    "            return jp.linalg.norm(jp.sum(M, axis=0) - self.unit_effect)**2\n",
    "\n",
    "        @jax.jit\n",
    "        def consistent_min(V):\n",
    "            M = V.reshape(m, self.d)\n",
    "            return (M @ self.states).flatten()\n",
    "\n",
    "        @jax.jit\n",
    "        def consistent_max(V):\n",
    "            M = V.reshape(m, self.d)\n",
    "            return -(M @ self.states).flatten() + 1\n",
    "\n",
    "        i = 0\n",
    "        while i < max_iter:\n",
    "            V = np.random.randn(m*self.d)\n",
    "            result = sc.optimize.minimize(unity, V,\\\n",
    "                                jac=jax.jit(jax.jacrev(unity)),\\\n",
    "                                tol=1e-16,\\\n",
    "                                constraints=[{\"type\": \"ineq\",\\\n",
    "                                             \"fun\": consistent_min,\\\n",
    "                                             \"jac\": jax.jit(jax.jacrev(consistent_min))},\\\n",
    "                                            {\"type\": \"ineq\",\\\n",
    "                                             \"fun\": consistent_max,\\\n",
    "                                             \"jac\": jax.jit(jax.jacrev(consistent_max))}],\\\n",
    "                                options={\"maxiter\": 5000},\n",
    "                                method=\"SLSQP\")\n",
    "            M = result.x.reshape(m, self.d)\n",
    "            if self.valid_logical_measurement(M):\n",
    "                return M\n",
    "            i += 1\n",
    "    \n",
    "    def valid_logical_measurement(self, M):\n",
    "        return np.all(M @ self.states >= 0) and np.all(M @ self.states <= 1) and np.allclose(np.sum(M, axis=0), self.unit_effect)\n",
    "\n",
    "    def sample_states(self, n):\n",
    "        return np.vstack([np.ones((1, n)), sample_convex_hull(self.state_space, n).T])\n",
    "\n",
    "    def sample_logical_states(self, n, max_iter=100):\n",
    "        @jax.jit\n",
    "        def info_complete(V):\n",
    "            S = V.reshape(self.d-1, n)\n",
    "            S = jp.vstack([jp.ones(n).reshape(1, n), S])\n",
    "            return (jp.linalg.matrix_rank(S) - self.d).astype(float)**2\n",
    "\n",
    "        @jax.jit\n",
    "        def consistent_min(V):\n",
    "            S = V.reshape(self.d-1, n)\n",
    "            S = jp.vstack([jp.ones(n).reshape(1, n), S])\n",
    "            return (self.effects @ S).flatten()\n",
    "\n",
    "        @jax.jit\n",
    "        def consistent_max(V):\n",
    "            S = V.reshape(self.d-1, n)\n",
    "            S = jp.vstack([jp.ones(n).reshape(1, n), S])\n",
    "            return -(self.effects @ S).flatten() + 1\n",
    "\n",
    "        i = 0\n",
    "        while i < max_iter:\n",
    "            V = np.random.randn(n*(self.d-1))\n",
    "            result = sc.optimize.minimize(info_complete, V,\\\n",
    "                                jac=jax.jit(jax.jacrev(info_complete)),\\\n",
    "                                tol=1e-16,\\\n",
    "                                constraints=[{\"type\": \"ineq\",\\\n",
    "                                             \"fun\": consistent_min,\\\n",
    "                                             \"jac\": jax.jit(jax.jacrev(consistent_min))},\\\n",
    "                                            {\"type\": \"ineq\",\\\n",
    "                                             \"fun\": consistent_max,\\\n",
    "                                             \"jac\": jax.jit(jax.jacrev(consistent_max))}],\\\n",
    "                                options={\"maxiter\": 5000},\n",
    "                                method=\"SLSQP\")\n",
    "            S = result.x.reshape(self.d-1, n)\n",
    "            S = np.vstack([np.ones(n).reshape(1,n), S])\n",
    "            if self.valid_logical_states(S):\n",
    "                return S\n",
    "            i += 1\n",
    "\n",
    "    def valid_states(self, S):\n",
    "        m = S.shape[1]\n",
    "        A = self.state_space.equations[:, :-1]\n",
    "        b = self.state_space.equations[:, -1]\n",
    "        B = np.tile(b, (m,1)).T\n",
    "        print(S)\n",
    "        return np.all((- A @ S[1:, :] - B).flatten() >= 0)\n",
    "    \n",
    "    def valid_logical_states(self, S):\n",
    "        return np.all(self.effects @ S >= 0) and np.all(self.effects @ S <= 1)\n",
    "\n",
    "class GPTStates:\n",
    "    def __init__(self, states):\n",
    "        self.states = states\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.states.shape[1]\n",
    "    \n",
    "    def dim(self):\n",
    "        return self.states.shape[0]\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.states.T[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.states.T[key] = value\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.states.T.__iter__()\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return GPTStates(np.hstack([self.states, other.states]))\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return GPTStates(other*self.states)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self.__mul__(1/other)\n",
    "\n",
    "    def __and__(self, other):\n",
    "        return GPTStates(kron(self.states, other.states))\n",
    "    \n",
    "    def __mod__(self, f):\n",
    "        return GPTStates(np.array([f(e) for e in self.states.T]).T)\n",
    "\n",
    "    def __lshift__(self, other):  \n",
    "        return other @ self.states\n",
    "\n",
    "    def __rshift__(self, other):\n",
    "          return other @ np.linalg.pinv(self.states)\n",
    "    \n",
    "class GPTEffects:\n",
    "    def __init__(self, effects):\n",
    "        self.effects = effects\n",
    "        self.inverted = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.effects.shape[0]\n",
    "    \n",
    "    def dim(self):\n",
    "        return self.effects.shape[1]\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.effects[key]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.effects[key] = value\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.effects.__iter__()\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return GPTEffects(np.vstack([self.effects, other.effects]))\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return GPTEffects(other*self.effects)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self.__mul__(1/other)\n",
    "\n",
    "    def __and__(self, other):\n",
    "        return GPTEffects(kron(self.effects, other.effects))\n",
    "    \n",
    "    def __mod__(self, f):\n",
    "        return GPTEffects(np.array([f(e) for e in self.effects]).T)\n",
    "\n",
    "    def __lshift__(self, other):\n",
    "        if np.all(other >= 0) and np.all(other <= 1) and np.isclose(np.sum(other),1):\n",
    "            return np.linalg.pinv(self.effects) @ other\n",
    "        return self.effects @ other\n",
    "\n",
    "    def __invert__(self):\n",
    "        self.inverted = True if not self.inverted else False\n",
    "        return self\n",
    "\n",
    "    def __inverted__(self, A):\n",
    "        A = A if not self.inverted else spectral_inverse(A)\n",
    "        self.inverted = False if self.inverted else self.inverted\n",
    "        return A\n",
    "\n",
    "    def __or__(self, other):\n",
    "        if type(other) == GPTStates:\n",
    "            return self.__inverted__(self.effects @ other.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666e2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
